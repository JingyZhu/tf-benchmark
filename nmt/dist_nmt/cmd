python -m dist_nmt.nmt     --attention=scaled_luong     --src=vi --tgt=en     --vocab_prefix=/tmp/nmt_data/vocab      --train_prefix=/tmp/nmt_data/train     --dev_prefix=/tmp/nmt_data/tst2012      --test_prefix=/tmp/nmt_data/tst2013     --out_dir=/tmp/nmt_attention_model     --num_train_steps=12000     --steps_per_stats=10     --num_layers=2     --num_units=128     --dropout=0.2 --metrics=bleu --log_device_placement=True --num_train_workers=2 --override_loaded_hparams=True --ps_hosts=128.105.144.47:50020 --worker_hosts=128.105.144.47:50030,128.105.144.50:50030 --task_index=0 --job_name=worker